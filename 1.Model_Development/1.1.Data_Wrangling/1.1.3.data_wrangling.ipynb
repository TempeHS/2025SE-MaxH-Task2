{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the data as a local variable\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"1.1.4.Student_Scores_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with null values\n",
    "Null values during data analysis can cause runtime errors and unexpected results. It is important to identify null values and deal with them appropriately before training a model.\n",
    "\n",
    "The isnull().sum() method call returns the null values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hours_Studied                  0\n",
       "Attendance                     0\n",
       "Parental_Involvement           0\n",
       "Access_to_Resources            0\n",
       "Extracurricular_Activities     0\n",
       "Sleep_Hours                    0\n",
       "Previous_Scores                0\n",
       "Motivation_Level               0\n",
       "Internet_Access                0\n",
       "Tutoring_Sessions              0\n",
       "Family_Income                  0\n",
       "Teacher_Quality               78\n",
       "School_Type                    0\n",
       "Peer_Influence                 0\n",
       "Physical_Activity              0\n",
       "Learning_Disabilities          0\n",
       "Parental_Education_Level      90\n",
       "Distance_from_Home            67\n",
       "Gender                         0\n",
       "Exam_Score                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the null variables from the dataset you can either:\n",
    " - Remove a row with dropna() method call\n",
    " - Replace missing values with fillna() method call and use mean value for numerical columns because it causes minimal changes in mathematical analysis while maintaining original data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hours_Studied                  0\n",
       "Attendance                     0\n",
       "Parental_Involvement           0\n",
       "Access_to_Resources            0\n",
       "Extracurricular_Activities     0\n",
       "Sleep_Hours                    0\n",
       "Previous_Scores                0\n",
       "Motivation_Level               0\n",
       "Internet_Access                0\n",
       "Tutoring_Sessions              0\n",
       "Family_Income                  0\n",
       "Teacher_Quality                0\n",
       "School_Type                    0\n",
       "Peer_Influence                 0\n",
       "Physical_Activity              0\n",
       "Learning_Disabilities          0\n",
       "Parental_Education_Level      86\n",
       "Distance_from_Home            65\n",
       "Gender                         0\n",
       "Exam_Score                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values for teacher quality\n",
    "data_frame = data_frame.dropna(subset=['Teacher_Quality'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hours_Studied                  0\n",
       "Attendance                     0\n",
       "Parental_Involvement           0\n",
       "Access_to_Resources            0\n",
       "Extracurricular_Activities     0\n",
       "Sleep_Hours                    0\n",
       "Previous_Scores                0\n",
       "Motivation_Level               0\n",
       "Internet_Access                0\n",
       "Tutoring_Sessions              0\n",
       "Family_Income                  0\n",
       "Teacher_Quality                0\n",
       "School_Type                    0\n",
       "Peer_Influence                 0\n",
       "Physical_Activity              0\n",
       "Learning_Disabilities          0\n",
       "Parental_Education_Level       0\n",
       "Distance_from_Home            65\n",
       "Gender                         0\n",
       "Exam_Score                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values for parental education level\n",
    "data_frame = data_frame.dropna(subset=['Parental_Education_Level'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hours_Studied                 0\n",
       "Attendance                    0\n",
       "Parental_Involvement          0\n",
       "Access_to_Resources           0\n",
       "Extracurricular_Activities    0\n",
       "Sleep_Hours                   0\n",
       "Previous_Scores               0\n",
       "Motivation_Level              0\n",
       "Internet_Access               0\n",
       "Tutoring_Sessions             0\n",
       "Family_Income                 0\n",
       "Teacher_Quality               0\n",
       "School_Type                   0\n",
       "Peer_Influence                0\n",
       "Physical_Activity             0\n",
       "Learning_Disabilities         0\n",
       "Parental_Education_Level      0\n",
       "Distance_from_Home            0\n",
       "Gender                        0\n",
       "Exam_Score                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values for distance from home\n",
    "data_frame = data_frame.dropna(subset=['Distance_from_Home'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values were removed rather than replacing missing values as the features with null values were categorical data not numerical meaning finding the mean wouldn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates\n",
    "Duplicate data can have detrimental effects on the machine learning model and outcomes, such as reducing data diversity and representativeness, which can lead to overfitting or a biased model.\n",
    "\n",
    "The duplicated().sum() method call returns the count of duplicate rows in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drop_duplicates() method call can be then stored back onto the data_frame variable removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace data\n",
    "I have decided not to replace any data and modify any values. This is for simplicity as changing something like Gender to be lower case rather than uppercase would mean changing the other categorical columns which is time consuming and inneffective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "Outliers may skew the analysis on numerical columns so it is important to address and potentially remove them. After using the first and third quartile on numerical data outliers were identified but extreme values can represent patterns for the model to address and use to generalize across different types of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6378.000000\n",
      "mean       67.252117\n",
      "std         3.914217\n",
      "min        55.000000\n",
      "25%        65.000000\n",
      "50%        67.000000\n",
      "75%        69.000000\n",
      "max       101.000000\n",
      "Name: Exam_Score, dtype: float64\n",
      "Outliers are a Exam_Score above 85.5 or below 49.5\n"
     ]
    }
   ],
   "source": [
    "#get the inter-quartile range on the Exam_Score column\n",
    "print(data_frame['Exam_Score'].describe())\n",
    "Q1 = data_frame['Exam_Score'].quantile(0.10)\n",
    "Q3 = data_frame['Exam_Score'].quantile(0.90)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a Exam_Score above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Exam Score column is the target for our model so filtering through outliers is not effective. Though there is a score of 101 which is in theory not possible and has the possibility to skew data so it will be eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6376.000000\n",
      "mean       67.241688\n",
      "std         3.870260\n",
      "min        55.000000\n",
      "25%        65.000000\n",
      "50%        67.000000\n",
      "75%        69.000000\n",
      "max        99.000000\n",
      "Name: Exam_Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Remove single outlying value\n",
    "data_frame = data_frame[data_frame['Exam_Score'] <= 100]\n",
    "print(data_frame['Exam_Score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features to a common range\n",
    "Scaling the features makes it easier for machine learning algorithms to find the optimal solution, as the different scales of the features do not influence them. This table shows the IQR range for all numerical columns which can then be used to scale the features, making it easier to identify the ranges to scale within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics for each numerical column:\n",
      "                    count       mean        std   min   25%   50%   75%    max\n",
      "Hours_Studied      6607.0  19.975329   5.990594   1.0  16.0  20.0  24.0   44.0\n",
      "Attendance         6607.0  79.977448  11.547475  60.0  70.0  80.0  90.0  100.0\n",
      "Sleep_Hours        6607.0   7.029060   1.468120   4.0   6.0   7.0   8.0   10.0\n",
      "Previous_Scores    6607.0  75.070531  14.399784  50.0  63.0  75.0  88.0  100.0\n",
      "Tutoring_Sessions  6607.0   1.493719   1.230570   0.0   1.0   1.0   2.0    8.0\n",
      "Physical_Activity  6607.0   2.967610   1.031231   0.0   2.0   3.0   4.0    6.0\n",
      "Exam_Score         6607.0  67.235659   3.890456  55.0  65.0  67.0  69.0  101.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Dataset\n",
    "data_frame = pd.read_csv('1.1.4.Student_Scores_Data.csv')\n",
    "\n",
    "# Describe the dataset to get the required statistics\n",
    "description = data_frame.describe().T\n",
    "\n",
    "# Select only the required columns\n",
    "description = description[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
    "\n",
    "# Display the description table\n",
    "print(\"\\nDescriptive statistics for each numerical column:\")\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Hours_Studied'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Hours_Studied' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Attendance'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Attendance' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Sleep_Hours'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Sleep_Hours' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Previous_Scores'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Previous_Scores' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Tutoring_Sessions'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Tutoring_Sessions' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Physical_Activity'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Physical_Activity' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature = 'Exam_Score'\n",
    "\n",
    "# Get the minimum and maximum values for the 'Exam_Score' column\n",
    "MIN_BP = data_frame[scale_feature].min()\n",
    "MAX_BP = data_frame[scale_feature].max()\n",
    "\n",
    "# Apply min-max scaling\n",
    "data_frame[scale_feature] = (data_frame[scale_feature] - MIN_BP) / (MAX_BP - MIN_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Hours_Studied",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Attendance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sleep_Hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Previous_Scores",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tutoring_Sessions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Physical_Activity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Exam_Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "71f826a7-f5ff-4ef6-baf4-1815ddde2d0e",
       "rows": [
        [
         "count",
         "6607.0",
         "6607.0",
         "6607.0",
         "6607.0",
         "6607.0",
         "6607.0",
         "6607.0"
        ],
        [
         "mean",
         "0.44128672549551035",
         "0.49943620402603295",
         "0.5048433479642803",
         "0.5014106250945966",
         "0.18671484788860299",
         "0.49460168508147917",
         "0.2659925902040655"
        ],
        [
         "std",
         "0.1393161473622963",
         "0.2886868740370704",
         "0.24468670445724797",
         "0.28799568701518047",
         "0.15382130266550242",
         "0.17187184877118808",
         "0.08457512567960287"
        ],
        [
         "min",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "0.3488372093023256",
         "0.25",
         "0.3333333333333333",
         "0.26",
         "0.125",
         "0.3333333333333333",
         "0.21739130434782608"
        ],
        [
         "50%",
         "0.4418604651162791",
         "0.5",
         "0.5",
         "0.5",
         "0.125",
         "0.5",
         "0.2608695652173913"
        ],
        [
         "75%",
         "0.5348837209302325",
         "0.75",
         "0.6666666666666666",
         "0.76",
         "0.25",
         "0.6666666666666666",
         "0.30434782608695654"
        ],
        [
         "max",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours_Studied</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Previous_Scores</th>\n",
       "      <th>Tutoring_Sessions</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Exam_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6607.000000</td>\n",
       "      <td>6607.000000</td>\n",
       "      <td>6607.000000</td>\n",
       "      <td>6607.000000</td>\n",
       "      <td>6607.000000</td>\n",
       "      <td>6607.000000</td>\n",
       "      <td>6607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.441287</td>\n",
       "      <td>0.499436</td>\n",
       "      <td>0.504843</td>\n",
       "      <td>0.501411</td>\n",
       "      <td>0.186715</td>\n",
       "      <td>0.494602</td>\n",
       "      <td>0.265993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.139316</td>\n",
       "      <td>0.288687</td>\n",
       "      <td>0.244687</td>\n",
       "      <td>0.287996</td>\n",
       "      <td>0.153821</td>\n",
       "      <td>0.171872</td>\n",
       "      <td>0.084575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hours_Studied   Attendance  Sleep_Hours  Previous_Scores  \\\n",
       "count    6607.000000  6607.000000  6607.000000      6607.000000   \n",
       "mean        0.441287     0.499436     0.504843         0.501411   \n",
       "std         0.139316     0.288687     0.244687         0.287996   \n",
       "min         0.000000     0.000000     0.000000         0.000000   \n",
       "25%         0.348837     0.250000     0.333333         0.260000   \n",
       "50%         0.441860     0.500000     0.500000         0.500000   \n",
       "75%         0.534884     0.750000     0.666667         0.760000   \n",
       "max         1.000000     1.000000     1.000000         1.000000   \n",
       "\n",
       "       Tutoring_Sessions  Physical_Activity   Exam_Score  \n",
       "count        6607.000000        6607.000000  6607.000000  \n",
       "mean            0.186715           0.494602     0.265993  \n",
       "std             0.153821           0.171872     0.084575  \n",
       "min             0.000000           0.000000     0.000000  \n",
       "25%             0.125000           0.333333     0.217391  \n",
       "50%             0.125000           0.500000     0.260870  \n",
       "75%             0.250000           0.666667     0.304348  \n",
       "max             1.000000           1.000000     1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the scaled data\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[!important] You need to save the calculations for each dataset you scale for scaling new values for prediction. Use 1.1.2.data.records.md to record this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the wrangled data to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../1.2.Feature_Engineering/wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
